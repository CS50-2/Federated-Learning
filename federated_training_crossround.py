def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


# -*- coding: utf-8 -*-
"""Federated Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tE-M1T-9BL-HglL5A7asx4b31Sdyhcdq
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import numpy as np
import random
import os
import matplotlib.pyplot as plt
import csv
import pandas as pd
from datetime import datetime
import time
from fvcore.nn import FlopCountAnalysis


# Define the MLP model
class MLPModel(nn.Module):
    def __init__(self):
        super(MLPModel, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 200)  # First layer, input dimension 784 -> 200
        self.fc2 = nn.Linear(200, 200)  # Second floor, 200 -> 200
        self.fc3 = nn.Linear(200, 10)  # Output layer, 200 -> 10
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.view(x.size(0), -1)  #  (batch_size, 1, 28, 28) -> (batch_size, 784)
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)  
        return x


# Load the MNIST dataset
def load_mnist_data(data_path="./data"):
    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])

    if os.path.exists(os.path.join(data_path, "MNIST/raw/train-images-idx3-ubyte")):
        print(" MNIST dataset already exists, skip downloading! ")
    else:
        print(" Downloading MNIST dataset...")

    train_data = datasets.MNIST(root=data_path, train=True, transform=transform, download=True)
    test_data = datasets.MNIST(root=data_path, train=False, transform=transform, download=True)

    # visualize_mnist_samples(train_data)
    return train_data, test_data


# Display sample images of the dataset
def visualize_mnist_samples(dataset, num_samples=10):
    fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 1.2, 1.5))
    for i in range(num_samples):
        img, label = dataset[i]
        axes[i].imshow(img.squeeze(), cmap="gray")
        axes[i].set_title(label)
        axes[i].axis("off")
    plt.show()


def split_data_by_label(dataset, num_clients=10):
    """
    Manually divide the dataset, each client contains 10 categories, and customize the number of samples.
    :param dataset: original dataset (such as MNIST)
    :param num_clients: total number of clients
    :return: (client dataset, client data size)
    """

    # client_data_sizes = {
    #     0: {0: 600, 1: 700, 2: 600, 3: 600, 4: 500, 5: 500, 6: 100, 7: 100, 8: 100, 9: 100},
    #     1: {0: 700, 1: 600, 2: 600, 3: 600, 4: 500, 5: 100, 6: 100, 7: 100, 8: 100, 9: 600},
    #     2: {0: 500, 1: 600, 2: 700, 3: 600, 4: 100, 5: 100, 6: 100, 7: 100, 8: 600, 9: 500},
    #     3: {0: 600, 1: 600, 2: 500, 3: 100, 4: 100, 5: 100, 6: 100, 7: 500, 8: 500, 9: 700},
    #     4: {0: 600, 1: 500, 2: 100, 3: 100, 4: 100, 5: 100, 6: 600, 7: 700, 8: 500, 9: 500},
    #     5: {0: 500, 1: 100, 2: 100, 3: 100, 4: 100, 5: 600, 6: 500, 7: 600, 8: 700, 9: 600},
    #     6: {0: 100, 1: 100, 2: 100, 3: 100, 4: 700, 5: 500, 6: 600, 7: 500, 8: 500, 9: 600},
    #     7: {0: 100, 1: 100, 2: 100, 3: 600, 4: 500, 5: 600, 6: 500, 7: 600, 8: 500, 9: 100},
    #     8: {0: 100, 1: 100, 2: 500, 3: 500, 4: 600, 5: 500, 6: 600, 7: 500, 8: 100, 9: 100},
    #     9: {0: 100, 1: 700, 2: 600, 3: 600, 4: 600, 5: 500, 6: 600, 7: 100, 8: 100, 9: 100}
    # }
    client_data_sizes = {
        0: {0: 600},
        1: {1: 700},
        2: {2: 500},
        3: {3: 600},
        4: {4: 600},
        5: {5: 500},
        6: {6: 100},
        7: {7: 100},
        8: {8: 100},
        9: {9: 100}
    }



 # Count the data index of each category
    label_to_indices = {i: [] for i in range(10)} 
    for idx, (_, label) in enumerate(dataset):
        label_to_indices[label].append(idx)

# Initialize client data storage
    client_data_subsets = {}
    client_actual_sizes = {i: {label: 0 for label in range(10)} for i in range(num_clients)}  # 记录实际分配的数据量

    # Traverse each client and assign it the specified category of data
    for client_id, label_info in client_data_sizes.items():
        selected_indices = [] # Temporarily store all selected indexes 
        for label, size in label_info.items():
            # Ensure that the actual size of the category dataset is not exceeded
            available_size = len(label_to_indices[label])
            sample_size = min(available_size, size)

            if sample_size < size:
                print(f"Warning: Insufficient data for category {label}, client {client_id} can only retrieve {sample_size} samples (needed {size})")

            # Randomly draw samples from this category
            sampled_indices = random.sample(label_to_indices[label], sample_size)
            selected_indices.extend(sampled_indices)

            # Record the actual amount of data allocated
            client_actual_sizes[client_id][label] = sample_size

        # create PyTorch Subset
        client_data_subsets[client_id] = torch.utils.data.Subset(dataset, selected_indices)

    # Print the actual amount of data allocated to each client
    print("\nActual data distribution of each client:")
    for client_id, label_sizes in client_actual_sizes.items():
        print(f"Client {client_id}: {label_sizes}")

    return client_data_subsets, client_actual_sizes


# Local training function
def local_train(model, train_loader, epochs=5, lr=0.01):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr)
    model.train()
    for epoch in range(epochs):
        for batch_x, batch_y in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
    return model.state_dict()

#Record the loss during training in real time for Fedgra
def local_train_fedgra_loss(model, train_loader, epochs=5, lr=0.01):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr)
    model.train()
    loss_sq_sum = 0.0

    for epoch in range(epochs):
        for batch_x, batch_y in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            loss_sq_sum += loss.item() ** 2   

    h_i = loss_sq_sum 
    return model, h_i  

# Federated average aggregation function
def fed_avg(global_model, client_state_dicts, client_sizes):
    global_dict = global_model.state_dict()
    subkey = [sublist[0] for sublist in client_state_dicts]
    new_client_sizes = dict(([(key, client_sizes[key]) for key in subkey]))
    total_data = sum(sum(label_sizes.values()) for label_sizes in new_client_sizes.values())  # 计算所有客户端数据总量
    for key in global_dict.keys():
        global_dict[key] = sum(
            client_state[key] * (sum(new_client_sizes[client_id].values()) / total_data)
            for (client_id, client_state) in client_state_dicts
        )
    global_model.load_state_dict(global_dict)
    return global_model


# Evaluating the Model
def evaluate(model, test_loader):
    model.eval()
    criterion = nn.CrossEntropyLoss()
    correct, total, total_loss = 0, 0, 0.0
    with torch.no_grad():
        for batch_x, batch_y in test_loader:
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += batch_y.size(0)
            correct += (predicted == batch_y).sum().item()
    accuracy = correct / total * 100
    return total_loss / len(test_loader), accuracy

# Entropy Weight Method Implementation

def entropy_weight(l):
    l = np.array(l)
    
    # Step 1: Min-Max 
    X_norm = (l - l.min(axis=1, keepdims=True)) / (l.max(axis=1, keepdims=True) - l.min(axis=1, keepdims=True) + 1e-12)

    # Step 2: Convert to probability matrix P_ki
    P = X_norm / (X_norm.sum(axis=1, keepdims=True) + 1e-12)

    # Step 3: Calculating Entropy
    K = 1 / np.log(X_norm.shape[1])
    E = -K * np.sum(P * np.log(P + 1e-12), axis=1)  # shape: (2,)

    # Step 4: Calculate information utility value & weight
    d = 1 - E
    weights = d / np.sum(d)
    return weights.tolist()


# Grey correlation implementation
def calculate_GRC(global_model, client_models, client_losses):
    """
    Calculate GRC score + entropy weights
    Fixes:
    - Wrong mapping order
    - Entropy weights use wrong metrics
    """
    # calculate the L2 norm
    param_diffs = []
    for model in client_models:
        global_vec = torch.nn.utils.parameters_to_vector(global_model.parameters()).detach()
        local_vec = torch.nn.utils.parameters_to_vector(model.parameters()).detach()
        diff = torch.norm(local_vec - global_vec).item()
        param_diffs.append(diff)

    # Map the original index to the [0, 1] interval (for entropy weight method)
    def map_sequence_loss(sequence):
        max_val, min_val = max(sequence), min(sequence)
        denom = max_val - min_val if abs(max_val - min_val) > 1e-8 else 1e-8
        return [(max_val - x) / denom for x in sequence]  # The smaller the better, negative correlation

    def map_sequence_diff(sequence):
        max_val, min_val = max(sequence), min(sequence)
        denom = max_val - min_val if abs(max_val - min_val) > 1e-8 else 1e-8
        return [(x - min_val) / denom for x in sequence]  # positive

    # Mapping for GRC
    mapped_losses = map_sequence_loss(client_losses)
    mapped_diffs = map_sequence_diff(param_diffs)

    #  Calculate weights using entropy weight method (based on mapping values, not GRC)
    grc_metrics = np.vstack([mapped_losses, mapped_diffs])  # shape: (2, n_clients)
    weights = entropy_weight(grc_metrics)  # w_loss, w_diff

    #  Calculate the GRC score (ξki), with a reference value of 1
    ref_loss, ref_diff = 1.0, 1.0
    delta_losses = [abs(x - ref_loss) for x in mapped_losses]
    delta_diffs = [abs(x - ref_diff) for x in mapped_diffs]
    all_deltas = delta_losses + delta_diffs
    max_delta, min_delta = max(all_deltas), min(all_deltas)

    grc_losses = []
    grc_diffs = []
    rho = 0.5 
    for d_loss, d_diff in zip(delta_losses, delta_diffs):
        grc_loss = (min_delta + rho * max_delta) / (d_loss + rho * max_delta)
        grc_diff = (min_delta + rho * max_delta) / (d_diff + rho * max_delta)
        grc_losses.append(grc_loss)
        grc_diffs.append(grc_diff)

    #  Weighted sum to get the final GRC score
    grc_losses = np.array(grc_losses)
    grc_diffs = np.array(grc_diffs)
    weighted_score = grc_losses * weights[0] + grc_diffs * weights[1]

    # Debug (loss, diff, score for each client)
    print("\n GRC scores]")
    for i in range(len(client_models)):
        print(f"Client {i} | loss: {client_losses[i]:.4f}, diff: {param_diffs[i]:.4f}, "
              f"mapped_loss: {mapped_losses[i]:.4f}, mapped_diff: {mapped_diffs[i]:.4f}, "
              f"GRC: {weighted_score[i]:.4f}")
    print(f"Entropy weight method: w_loss = {weights[0]:.4f}, w_diff = {weights[1]:.4f}")

    return weighted_score, weights


# Client selector
def select_clients(client_loaders, use_all_clients=False, num_select=None,
                   select_by_loss=False, global_model=None, grc=False,
                   fairness_tracker=None):  

    if grc:  #Using GRC to select clients
        client_models = []
        # Train the local model and calculate the loss
        client_losses = []
        for client_id, client_loader in client_loaders.items():
            local_model = MLPModel()
            local_model.load_state_dict(global_model.state_dict())  # Synchronize global model
            trained_model, h_i = local_train_fedgra_loss(local_model, client_loader, epochs=5, lr=0.01)
            client_models.append(trained_model)
            client_losses.append(h_i)

        #  Calculate the GRC score
        grc_scores, grc_weights = calculate_GRC(global_model, client_models, client_losses)
        select_clients.latest_weights = grc_weights 
        #  Sort by GRC score (from high to low, the higher the GRC, the better)
        client_grc_pairs = list(zip(client_loaders.keys(), grc_scores))
        client_grc_pairs.sort(key=lambda x: x[1], reverse=True)  

        # Select the first num_select clients with the highest GRC
        selected_clients = [client_id for client_id, _ in client_grc_pairs[:num_select]]
        return selected_clients

 # The rest of the selection logic remains unchanged

    if use_all_clients is True:
        print("Selecting all clients")
        return list(client_loaders.keys())

    if num_select is None:
        raise ValueError("If use_all_clients=False, num_select cannot be None!")

    if select_by_loss and global_model:
        client_losses = {}
        
        for client_id, loader in client_loaders.items():
            local_model = MLPModel()
            local_model.load_state_dict(global_model.state_dict())
            local_train(local_model, loader, epochs=5, lr=0.01) 
            loss, _ = evaluate(local_model, loader)  
            client_losses[client_id] = loss
        selected_clients = sorted(client_losses, key=client_losses.get, reverse=True)[:num_select]
        print(f"Selected {num_select} clients with the highest loss: {selected_clients}")
    else:
        selected_clients = random.sample(list(client_loaders.keys()), num_select)
        print(f"Randomly selected {num_select} clients: {selected_clients}")

    return selected_clients


def update_communication_counts(communication_counts, selected_clients, event):
    """
    Client communication count
    - event='receive' indicates that the client receives the global model
    - event='send' indicates that the client uploads the local model
    - event='full_round' is only incremented when the client completes the full send and receive
    """
    for client_id in selected_clients:
        communication_counts[client_id][event] += 1

        # Increase full_round only when the client completes a full send and receive
        if event == "send" and communication_counts[client_id]['receive'] > 0:
            communication_counts[client_id]['full_round'] += 1


def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def compute_model_flops(
    model, input_shape=(1, 1, 28, 28), batch_size=1,
    num_samples=1, epochs=1, backward=True,
    verbose=False, freeze=False, freeze_layers=1,
    prune=False, prune_ratio=0.3, brute_prune=False
):
    """
    Calculate the total FLOPs in the training phase (estimate)
    :param model: PyTorch model
    :param input_shape: Input shape of a single sample (e.g. (1, 28, 28) for MNIST)
    :param batch_size: Number of samples input each time
    :param num_samples: How many training samples does the client have in total
    :param epochs: How many epochs are trained per round
    :param backward_factor: How many times is the backward FLOPs of the forward (usually 2~3)
    :param verbose: Whether to print the FLOPs of each layer
    :return: Estimated total FLOPs
    """
    model.eval()
    dummy_input = torch.randn((batch_size, *input_shape[1:]))  
    flops_analyzer = FlopCountAnalysis(model, dummy_input)

    if backward:
        if freeze:
            if freeze_layers == 1:
                backward_factor = 1.9  # Freeze fc1
            elif freeze_layers >= 2:
                backward_factor = 1.42  # Freeze fc1 + fc2
            else:
                backward_factor = 3.0  
        elif prune:
            if prune_ratio >= 0.6:
                backward_factor = 1.6
            elif prune_ratio >= 0.3:
                backward_factor = 1.7
            else:
                backward_factor = 1.8  
        elif brute_prune:
            backward_factor = 1.5  
        else:
            backward_factor = 3.0  
    else:
        backward_factor = 0.0  

    if verbose:
        print(flops_analyzer.by_module())  
        print(f" 单个 batch 的 forward FLOPs: {flops_analyzer.total() / 1e6:.2f} MFLOPs")

    # Forward FLOPs for a single batch
    forward_flops_per_batch = flops_analyzer.total()

    # Training FLOPs ≈ (forward + backward) × number of batches × epoch
    num_batches = int(np.ceil(num_samples / batch_size))
    total_training_flops = forward_flops_per_batch * (1 + backward_factor) * num_batches * epochs

    return total_training_flops

def main():
    import time
    torch.manual_seed(42)
    random.seed(42)
    np.random.seed(42)

    # Load the MNIST dataset
    train_data, test_data = load_mnist_data()
    client_datasets, client_data_sizes = split_data_by_label(train_data)
    client_loaders = {client_id: data.DataLoader(dataset, batch_size=32, shuffle=True)
                      for client_id, dataset in client_datasets.items()}
    test_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)

    global_model = MLPModel()
    print(f" Total trainable parameters: {count_parameters(global_model):,}")
    global_accuracies = []
    total_communication_counts = []
    rounds = 500
    use_all_clients = False
    num_selected_clients = 2
    use_loss_based_selection = False
    grc = True

    communication_counts = {client_id: {'send': 0, 'receive': 0, 'full_round': 0} for client_id in client_loaders}
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"training_data_{timestamp}.csv"
    csv_data = []

    for r in range(rounds):
        start_time = time.time()
        print(f"\n 第 {r + 1} 轮聚合")

        selected_clients = select_clients(
            client_loaders,
            use_all_clients=use_all_clients,
            num_select=num_selected_clients,
            select_by_loss=use_loss_based_selection,
            global_model=global_model,
            grc=grc
        )

        update_communication_counts(communication_counts, selected_clients, "receive")
        client_state_dicts = []
        total_flops_this_round = 0 
        
        for client_id in selected_clients:
            client_loader = client_loaders[client_id]
            local_model = MLPModel()
            local_model.load_state_dict(global_model.state_dict())
            # Flops statistics
            flops = compute_model_flops(
            local_model,
            input_shape=(1, 1, 28, 28),
            batch_size=32,
            num_samples=sum(client_data_sizes[client_id].values()),
            epochs=5,
            backward=True
            )
            total_flops_this_round += flops
            local_state = local_train(local_model, client_loader, epochs=5, lr=0.01)
            client_state_dicts.append((client_id, local_state))
            update_communication_counts(communication_counts, [client_id], "send")

            param_mean = {name: param.mean().item() for name, param in local_model.named_parameters()}
            print(f"   client {client_id} Training completed | Sample size: {sum(client_data_sizes[client_id].values())}")
            print(f"   client {client_id} Model parameter mean: {param_mean}")

        total_send = sum(communication_counts[c]['send'] - (communication_counts[c]['full_round'] - 1) for c in selected_clients)
        total_receive = sum(communication_counts[c]['receive'] - (communication_counts[c]['full_round'] - 1) for c in selected_clients)
        total_comm = total_send + total_receive

        if len(total_communication_counts) > 0:
            total_comm += total_communication_counts[-1]
        total_communication_counts.append(total_comm)

        global_model = fed_avg(global_model, client_state_dicts, client_data_sizes)

        loss, accuracy = evaluate(global_model, test_loader)
        global_accuracies.append(accuracy)
        print(f" Test set loss: {loss:.4f} | Test set accuracy:{accuracy:.2f}%")

        if grc and hasattr(select_clients, 'latest_weights'):
            w_loss = select_clients.latest_weights[0]
            w_diff = select_clients.latest_weights[1]
            print(f" Round {r+1} | GRC weight: w_loss = {w_loss:.4f}, w_diff = {w_diff:.4f}")
        else:
            w_loss = 'NA'
            w_diff = 'NA'

        # Parameter statistics
        params_per_model = count_parameters(global_model)
        total_params_this_round = len(client_state_dicts) * params_per_model

        elapsed_time = time.time() - start_time
        csv_data.append([
            r + 1, accuracy, total_comm,
            ",".join(map(str, selected_clients)),
            w_loss, w_diff, elapsed_time, total_params_this_round, total_flops_this_round
        ])

        df = pd.DataFrame(csv_data, columns=[
            'Round', 'Accuracy', 'Total communication counts', 'Selected Clients',
            'GRC Weight - Loss', 'GRC Weight - Diff', 'Time', 'Total Active Parameters','Total FLOPs'
        ])
        df.to_csv(csv_filename, index=False)

    final_loss, final_accuracy = evaluate(global_model, test_loader)
    print(f"\n Loss of final model test dataset: {final_loss:.4f}")
    print(f" Final model test set accuracy: {final_accuracy:.2f}%")

    print("\n Client Communication Statistics:")
    for client_id, counts in communication_counts.items():
        print(f"Client {client_id}: Sent {counts['send']} times, Received {counts['receive']} times, Completed full_round {counts['full_round']} times")



def main2():
    import time
    import torch
    import random
    import numpy as np
    import pandas as pd
    from datetime import datetime

    torch.manual_seed(0)
    random.seed(0)
    np.random.seed(0)

    train_data, test_data = load_mnist_data()
    client_datasets, client_data_sizes = split_data_by_label(train_data)
    client_loaders = {client_id: data.DataLoader(dataset, batch_size=32, shuffle=True)
                      for client_id, dataset in client_datasets.items()}
    test_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)

    global_model = MLPModel()
    print(f" Total trainable parameters: {count_parameters(global_model):,}")
    global_accuracies = []
    total_communication_counts = []
    rounds = 300
    num_selected_clients = 2

    communication_counts = {cid: {'send': 0, 'receive': 0, 'full_round': 0} for cid in client_loaders}
    client_loss_history = {cid: [] for cid in client_loaders}
    local_model_cache = {}
    selected_clients = []

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"training_data_{timestamp}_main2.csv"
    csv_data = []

    total_comm = 0

    for r in range(rounds):
        start_time = time.time()
        print(f"\n The {r + 1} Wheel aggregation")
        is_comm_round = (r % 3 == 0)
        total_flops_this_round = 0  

        if is_comm_round:
            weighted_losses = {}
            for cid in client_loaders:
                loss, _ = evaluate(global_model, client_loaders[cid])
                client_loss_history[cid].append(loss)
                history = client_loss_history[cid][-3:]
                if len(history) == 3:
                    weights = [0.7, 0.2, 0.1]
                elif len(history) == 2:
                    weights = [0.8, 0.2]
                else:
                    weights = [1.0]
                weighted_losses[cid] = sum(h * w for h, w in zip(history, weights)) / sum(weights)

            selected_clients = sorted(weighted_losses, key=weighted_losses.get, reverse=True)[:num_selected_clients]
            print(f" Communication round | Selected clients: {selected_clients}")
            update_communication_counts(communication_counts, selected_clients, "receive")
        else:
            print(f" Non-communication round | Reuse client model: {selected_clients}")

        client_state_dicts = []
        for cid in selected_clients:
            if is_comm_round:
                loader = client_loaders[cid]
                model = MLPModel()
                model.load_state_dict(global_model.state_dict())
                flops = compute_model_flops(
                    model,
                    input_shape=(1, 1, 28, 28),
                    batch_size=32,
                    num_samples=sum(client_data_sizes[cid].values()),
                    epochs=1,
                    backward=True
                )
                total_flops_this_round += flops
                
                local_train(model, loader, epochs=1, lr=0.01)
                local_model_cache[cid] = model
                client_state_dicts.append((cid, model.state_dict()))
                update_communication_counts(communication_counts, [cid], "send")
                total_comm += 2
            else:
                if cid in local_model_cache:
                    client_state_dicts.append((cid, local_model_cache[cid].state_dict()))
                else:
                    print(f"client {cid} No model cache, skipping")

        total_communication_counts.append(total_comm)
        global_model = fed_avg(global_model, client_state_dicts, client_data_sizes)

        loss, acc = evaluate(global_model, test_loader)
        global_accuracies.append(acc)
        print(f" Test set loss: {loss:.4f} | Test set accuracy: {acc:.2f}%")

        # Parameter statistics (only communication rounds are counted)
        if is_comm_round:
            params_per_model = count_parameters(global_model)
            total_params_this_round = len(client_state_dicts) * params_per_model
        else:
            total_params_this_round = 0

        elapsed_time = time.time() - start_time
        csv_data.append([
            r + 1, acc, total_comm,
            ",".join(map(str, selected_clients)), 'NA', 'NA', elapsed_time, total_params_this_round, total_flops_this_round
        ])

        df = pd.DataFrame(csv_data, columns=[
            'Round', 'Accuracy', 'Total communication counts', 'Selected Clients',
            'GRC Weight - Loss', 'GRC Weight - Diff', 'Time', 'Total Active Parameters', 'Total FLOPs'
        ])
        df.to_csv(csv_filename, index=False)

    final_loss, final_acc = evaluate(global_model, test_loader)
    print(f"\n Final Loss: {final_loss:.4f}")
    print(f" Final Accuracy: {final_acc:.2f}%")


# Fedgra fixed cross-round selection

def main3():
    import time
    import torch
    import random
    import numpy as np
    import pandas as pd
    from datetime import datetime

    torch.manual_seed(0)
    random.seed(0)
    np.random.seed(0)

    train_data, test_data = load_mnist_data()
    client_datasets, client_data_sizes = split_data_by_label(train_data)
    client_loaders = {cid: data.DataLoader(dataset, batch_size=32, shuffle=True) for cid, dataset in client_datasets.items()}
    test_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)

    global_model = MLPModel()
    print(f" Total trainable parameters: {count_parameters(global_model):,}")
    global_accuracies = []
    total_communication_counts = []
    rounds = 300
    num_selected_clients = 2

    # Initialize communication records, cache, GRC history
    communication_counts = {cid: {'send': 0, 'receive': 0, 'full_round': 0} for cid in client_loaders}
    local_model_cache = {}  #Store client model, used in non-communication rounds
    client_grc_history = {cid: [] for cid in client_loaders}  # Storing GRC history
    selected_clients = []  # Selection results for each round

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"training_data_{timestamp}_main3.csv"
    csv_data = []

    total_comm = 0  

    for r in range(rounds):
        start_time = time.time()
        print(f"\n The {r + 1} averrage")
        w_loss, w_diff = 'NA', 'NA'
        round_comm = 0
        is_comm_round = (r % 3 == 0)
        total_flops_this_round = 0  

        client_state_dicts = []

        if is_comm_round:
            print(" Communication round")
            client_models, client_losses = [], []
            for cid, loader in client_loaders.items():
                model = MLPModel()
                model.load_state_dict(global_model.state_dict())
                local_train(model, loader, epochs=1, lr=0.01)
                client_models.append(model)
                loss, _ = evaluate(model, loader)
                client_losses.append(loss)

            # Calculate GRC score and store it
            grc_scores, grc_weights = calculate_GRC(global_model, client_models, client_losses)
            w_loss, w_diff = grc_weights

            for i, cid in enumerate(client_loaders.keys()):
                client_grc_history[cid].append(grc_scores[i])

            # Weighted average based on historical GRC
            weighted_grc = {}
            for cid in client_loaders:
                history = client_grc_history[cid][-3:]
                if len(history) == 3:
                    weights = [0.7, 0.2, 0.1]
                elif len(history) == 2:
                    weights = [0.8, 0.2]
                else:
                    weights = [1.0]
                weighted_grc[cid] = sum(h * w for h, w in zip(history, weights)) / sum(weights)

            
            selected_clients = sorted(weighted_grc, key=weighted_grc.get, reverse=True)[:num_selected_clients]
            print(f" Selected Clients: {selected_clients}")

            update_communication_counts(communication_counts, selected_clients, "receive")

            
            for cid in selected_clients:
                model = MLPModel()
                model.load_state_dict(global_model.state_dict())
                
                flops = compute_model_flops(
                    model,
                    input_shape=(1, 1, 28, 28),
                    batch_size=32,
                    num_samples=sum(client_data_sizes[cid].values()),
                    epochs=1,
                    backward=True
                )
                total_flops_this_round += flops
                
                local_train(model, client_loaders[cid], epochs=1, lr=0.01)
                local_model_cache[cid] = model  
                client_state_dicts.append((cid, model.state_dict()))
                update_communication_counts(communication_counts, [cid], "send")
                round_comm += 2

        else:
            print(f" Non-Communication Wheel | Reuse Model:{selected_clients}")
            for cid in selected_clients:
                if cid in local_model_cache:
                    client_state_dicts.append((cid, local_model_cache[cid].state_dict()))
                else:
                    print(f" Missing cache, client {cid} ")

        # Accumulate the number of communications
        total_comm += round_comm
        total_communication_counts.append(total_comm)

        # Aggregate global model
        global_model = fed_avg(global_model, client_state_dicts, client_data_sizes)

        loss, acc = evaluate(global_model, test_loader)
        global_accuracies.append(acc)
        print(f" Loss: {loss:.4f} | Accuracy: {acc:.2f}%")


        if is_comm_round:
            params_per_model = count_parameters(global_model)
            total_params_this_round = len(client_state_dicts) * params_per_model
        else:
            total_params_this_round = 0


        elapsed_time = time.time() - start_time
        csv_data.append([
            r + 1, acc, total_comm,
            ",".join(map(str, selected_clients)), w_loss, w_diff,
            elapsed_time, total_params_this_round, total_flops_this_round  
        ])

        df = pd.DataFrame(csv_data, columns=[
            'Round', 'Accuracy', 'Total communication counts', 'Selected Clients',
            'GRC Weight - Loss', 'GRC Weight - Diff', 'Time', 'Total Active Parameters', 'Total FLOPs'
        ])
        df.to_csv(csv_filename, index=False)


    final_loss, final_acc = evaluate(global_model, test_loader)
    print(f"\n Final Loss: {final_loss:.4f}")
    print(f" Final Accuracy: {final_acc:.2f}%")

def main4():
    import time
    torch.manual_seed(0)
    random.seed(0)
    np.random.seed(0)

    train_data, test_data = load_mnist_data()
    client_datasets, client_data_sizes = split_data_by_label(train_data)
    client_loaders = {cid: data.DataLoader(dataset, batch_size=32, shuffle=True) for cid, dataset in client_datasets.items()}
    test_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)

    global_model = MLPModel()
    print(f" Total trainable parameters: {count_parameters(global_model):,}")
    global_accuracies = []
    total_communication_counts = []
    rounds = 300
    num_selected_clients = 2

    communication_counts = {cid: {'send': 0, 'receive': 0, 'full_round': 0} for cid in client_loaders}
    local_model_cache = {}
    client_grc_history = {cid: [] for cid in client_loaders}
    selected_clients = []

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"training_data_{timestamp}_main4.csv"
    csv_data = []

    total_comm = 0

    # Dynamic communication mechanism variables
    prev_loss = None
    skip_count = 0
    max_skip = 6  # Maximum number of consecutive skips allowed
    base_threshold = 0.02  # Initial threshold

    for r in range(rounds):
        start_time = time.time()
        print(f"\n Round {r + 1} aggregation")

        # Dynamically adjust threshold (decays each round)
        comm_threshold = max(0.002, base_threshold * (0.995 ** r))

        w_loss, w_diff = 'NA', 'NA'
        round_comm = 0

        # Evaluate current model performance before decision
        curr_loss, acc = evaluate(global_model, test_loader)
        global_accuracies.append(acc)

        # Determine if this is a communication round
        if prev_loss is None:
            is_comm_round = True
        elif skip_count >= max_skip:
            is_comm_round = True
        else:
            is_comm_round = abs(prev_loss - curr_loss) > comm_threshold

        prev_loss = curr_loss
        skip_count = 0 if is_comm_round else skip_count + 1

        print(f" Is communication round: {is_comm_round} (skip count: {skip_count}, threshold: {comm_threshold:.5f})")

        client_state_dicts = []

        if is_comm_round:
            client_models, client_losses = [], []
            for cid, loader in client_loaders.items():
                model = MLPModel()
                model.load_state_dict(global_model.state_dict())
                local_train(model, loader, epochs=1, lr=0.01)
                client_models.append(model)
                loss, _ = evaluate(model, loader)
                client_losses.append(loss)

            grc_scores, grc_weights = calculate_GRC(global_model, client_models, client_losses)
            w_loss, w_diff = grc_weights

            for i, cid in enumerate(client_loaders.keys()):
                client_grc_history[cid].append(grc_scores[i])

            weighted_grc = {}
            for cid in client_loaders:
                history = client_grc_history[cid][-3:]
                weights = [0.7, 0.2, 0.1] if len(history) == 3 else [0.8, 0.2] if len(history) == 2 else [1.0]
                weighted_grc[cid] = sum(h * w for h, w in zip(history, weights)) / sum(weights)

            selected_clients = sorted(weighted_grc, key=weighted_grc.get, reverse=True)[:num_selected_clients]
            print(f" Selected Clients: {selected_clients}")

            update_communication_counts(communication_counts, selected_clients, "receive")

            for cid in selected_clients:
                model = MLPModel()
                model.load_state_dict(global_model.state_dict())
                local_train(model, client_loaders[cid], epochs=1, lr=0.01)
                local_model_cache[cid] = model
                client_state_dicts.append((cid, model.state_dict()))
                update_communication_counts(communication_counts, [cid], "send")
                round_comm += 2

        else:
            print(f" Non-communication round | Reusing models: {selected_clients}")
            for cid in selected_clients:
                if cid in local_model_cache:
                    client_state_dicts.append((cid, local_model_cache[cid].state_dict()))
                else:
                    print(f" Cache missing, client {cid} skipped")

        total_comm += round_comm
        total_communication_counts.append(total_comm)

        global_model = fed_avg(global_model, client_state_dicts, client_data_sizes)

        print(f" Loss: {curr_loss:.4f} | Accuracy: {acc:.2f}%")

        params_this_round = len(client_state_dicts) * count_parameters(global_model) if is_comm_round else 0

        csv_data.append([
            r + 1, acc, total_comm,
            ",".join(map(str, selected_clients)), w_loss, w_diff,
            time.time() - start_time, params_this_round,
            int(is_comm_round)
        ])

        df = pd.DataFrame(csv_data, columns=[
            'Round', 'Accuracy', 'Total communication counts', 'Selected Clients',
            'GRC Weight - Loss', 'GRC Weight - Diff', 'Time', 'Total Active Parameters',
            'Is Communication Round'
        ])
        df.to_csv(csv_filename, index=False)

    final_loss, final_acc = evaluate(global_model, test_loader)
    print(f"\n Final Loss: {final_loss:.4f}")
    print(f" Final Accuracy: {final_acc:.2f}%")

    
def main5():

    torch.manual_seed(0)
    random.seed(0)
    np.random.seed(0)

    train_data, test_data = load_mnist_data()
    client_datasets, client_data_sizes = split_data_by_label(train_data)
    client_loaders = {cid: data.DataLoader(dataset, batch_size=32, shuffle=True) for cid, dataset in client_datasets.items()}
    test_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)

    global_model = MLPModel()
    print(f" Total trainable parameters: {count_parameters(global_model):,}")
    global_accuracies = []
    total_communication_counts = []
    rounds = 300
    num_selected_clients = 2

    communication_counts = {cid: {'send': 0, 'receive': 0, 'full_round': 0} for cid in client_loaders}
    local_model_cache = {}
    client_grc_history = {cid: [] for cid in client_loaders}
    selected_clients = []

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"training_data_{timestamp}_main5_pro2.csv"
    csv_data = []

    total_comm = 0

    # Dynamic communication mechanism variables
    prev_loss = None
    recent_losses = []
    skip_count = 0
    max_skip = 3
    comm_threshold = 0.01  # Loss-based control only

    for r in range(rounds):
        start_time = time.time()
        print(f"\n Round {r + 1} aggregation")

        w_loss, w_diff = 'NA', 'NA'
        round_comm = 0

        curr_loss, curr_acc = evaluate(global_model, test_loader)
        global_accuracies.append(curr_acc)

        # Sliding average of loss (window = 3)
        recent_losses.append(curr_loss)
        if len(recent_losses) > 3:
            recent_losses.pop(0)
        avg_loss = sum(recent_losses) / len(recent_losses)

        # Determine if this is a communication round
        if r < 10:
            is_comm_round = True  # Warm-up period
        elif skip_count >= max_skip:
            is_comm_round = True
        else:
            is_comm_round = abs(prev_loss - avg_loss) > comm_threshold if prev_loss is not None else True

        skip_count = 0 if is_comm_round else skip_count + 1
        prev_loss = avg_loss

        print(f" Is communication round: {is_comm_round} (skipped: {skip_count}, AvgLoss: {avg_loss:.4f}, Threshold: {comm_threshold:.5f})")

        client_state_dicts = []
        total_flops_this_round = 0  # FLOPs this round

        if is_comm_round:
            client_models, client_losses = [], []
            for cid, loader in client_loaders.items():
                model = MLPModel()
                model.load_state_dict(global_model.state_dict())
                local_train(model, loader, epochs=1, lr=0.01)
                client_models.append(model)
                loss, _ = evaluate(model, loader)
                client_losses.append(loss)

            grc_scores, grc_weights = calculate_GRC(global_model, client_models, client_losses)
            w_loss, w_diff = grc_weights

            for i, cid in enumerate(client_loaders.keys()):
                client_grc_history[cid].append(grc_scores[i])

            weighted_grc = {}
            for cid in client_loaders:
                history = client_grc_history[cid][-3:]
                weights = [0.7, 0.2, 0.1] if len(history) == 3 else [0.8, 0.2] if len(history) == 2 else [1.0]
                weighted_grc[cid] = sum(h * w for h, w in zip(history, weights)) / sum(weights)

            selected_clients = sorted(weighted_grc, key=weighted_grc.get, reverse=True)[:num_selected_clients]
            print(f" Selected Clients: {selected_clients}")

            update_communication_counts(communication_counts, selected_clients, "receive")

            for cid in selected_clients:
                model = MLPModel()
                model.load_state_dict(global_model.state_dict())
                # ===== FLOPs computation =====
                flops = compute_model_flops(
                    model,
                    input_shape=(1, 1, 28, 28),
                    batch_size=32,
                    num_samples=sum(client_data_sizes[cid].values()),
                    epochs=1,
                    backward=True
                )
                total_flops_this_round += flops
                # ============================
                local_train(model, client_loaders[cid], epochs=1, lr=0.01)
                local_model_cache[cid] = model
                client_state_dicts.append((cid, model.state_dict()))
                update_communication_counts(communication_counts, [cid], "send")
                round_comm += 2

        else:
            print(f" Non-communication round | Reusing models: {selected_clients}")
            for cid in selected_clients:
                if cid in local_model_cache:
                    client_state_dicts.append((cid, local_model_cache[cid].state_dict()))
                else:
                    print(f" Cache missing, client {cid} skipped")

        total_comm += round_comm
        total_communication_counts.append(total_comm)

        global_model = fed_avg(global_model, client_state_dicts, client_data_sizes)

        print(f" Loss: {curr_loss:.4f} | Accuracy: {curr_acc:.2f}%")

        params_this_round = len(client_state_dicts) * count_parameters(global_model) if is_comm_round else 0

        csv_data.append([
            r + 1, curr_acc, total_comm,
            ",".join(map(str, selected_clients)), w_loss, w_diff,
            time.time() - start_time, params_this_round, total_flops_this_round
        ])

        df = pd.DataFrame(csv_data, columns=[
            'Round', 'Accuracy', 'Total communication counts', 'Selected Clients',
            'GRC Weight - Loss', 'GRC Weight - Diff', 'Time', 'Total Active Parameters',
            'Total FLOPs'
        ])
        df.to_csv(csv_filename, index=False)

    final_loss, final_acc = evaluate(global_model, test_loader)
    print(f"\n Final Loss: {final_loss:.4f}")
    print(f" Final Accuracy: {final_acc:.2f}%")

if __name__ == "__main__":
    main()
