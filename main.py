# -*- coding: utf-8 -*-
"""Federated Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tE-M1T-9BL-HglL5A7asx4b31Sdyhcdq
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import numpy as np
import random
import os
import matplotlib.pyplot as plt
import csv
import pandas as pd
from datetime import datetime


# å®šä¹‰ MLP æ¨¡å‹
class MLPModel(nn.Module):
    def __init__(self):
        super(MLPModel, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 200)  # ç¬¬ä¸€å±‚ï¼Œè¾“å…¥ç»´åº¦ 784 -> 200
        self.fc2 = nn.Linear(200, 200)  # ç¬¬äºŒå±‚ï¼Œ200 -> 200
        self.fc3 = nn.Linear(200, 10)  # è¾“å‡ºå±‚ï¼Œ200 -> 10
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.view(x.size(0), -1)  # å±•å¹³è¾“å…¥ (batch_size, 1, 28, 28) -> (batch_size, 784)
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)  # ç›´æ¥è¾“å‡ºï¼Œä¸ä½¿ç”¨ Softmaxï¼ˆå› ä¸º PyTorch çš„ CrossEntropyLoss é‡Œå·²ç»åŒ…å«äº†ï¼‰
        return x


# åŠ è½½ MNIST æ•°æ®é›†
def load_mnist_data(data_path="./data"):
    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])

    if os.path.exists(os.path.join(data_path, "MNIST/raw/train-images-idx3-ubyte")):
        print("âœ… MNIST æ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½ã€‚")
    else:
        print("â¬‡ï¸ æ­£åœ¨ä¸‹è½½ MNIST æ•°æ®é›†...")

    train_data = datasets.MNIST(root=data_path, train=True, transform=transform, download=True)
    test_data = datasets.MNIST(root=data_path, train=False, transform=transform, download=True)

    # visualize_mnist_samples(train_data)
    return train_data, test_data


# æ˜¾ç¤ºæ•°æ®é›†ç¤ºä¾‹å›¾ç‰‡
def visualize_mnist_samples(dataset, num_samples=10):
    fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 1.2, 1.5))
    for i in range(num_samples):
        img, label = dataset[i]
        axes[i].imshow(img.squeeze(), cmap="gray")
        axes[i].set_title(label)
        axes[i].axis("off")
    plt.show()


# åˆ†å‰² MNIST æ•°æ®ï¼Œä½¿æ¯ä¸ªå®¢æˆ·ç«¯åªåŒ…å«æŸä¸ªæ•°å­—ç±»åˆ«
# def split_data_by_label(dataset):
#     # è‡ªå®šä¹‰æ¯ä¸ªç±»åˆ«çš„æ•°æ®é‡
#     client_data_sizes = {
#         0: 5000,
#         1: 7000,
#         2: 6000,
#         3: 8000,
#         4: 4000,
#         5: 9000,
#         6: 3000,
#         7: 10000,
#         8: 7500,
#         9: 6500
#     }

#     label_to_indices = {i: [] for i in range(10)}  # è®°å½•æ¯ä¸ªç±»åˆ«çš„ç´¢å¼•

#     # æ”¶é›†æ¯ä¸ªç±»åˆ«çš„æ•°æ®ç´¢å¼•
#     for idx, (_, label) in enumerate(dataset):
#         label_to_indices[label].append(idx)

#     # ä¸ºæ¯ä¸ª client é€‰æ‹©å¯¹åº”ç±»åˆ«çš„æ•°æ®ï¼Œå¹¶è£å‰ªæˆéœ€è¦çš„æ•°é‡
#     client_datasets = []
#     for label, size in client_data_sizes.items():
#         indices = label_to_indices[label][:size]  # å–å‰ size ä¸ªæ ·æœ¬
#         client_datasets.append((label, torch.utils.data.Subset(dataset, indices)))  # å­˜å‚¨ (ç±»åˆ«, æ•°æ®é›†)

#     print("ğŸ“Š å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒ:", client_data_sizes)
#     return client_datasets, client_data_sizes

def split_data_by_label(dataset, num_clients=10):
    """
    æ‰‹åŠ¨åˆ’åˆ†æ•°æ®é›†ï¼Œæ¯ä¸ªå®¢æˆ·ç«¯åŒ…å« 10 ä¸ªç±»åˆ«ï¼Œå¹¶è‡ªå®šä¹‰æ ·æœ¬æ•°é‡ã€‚
    :param dataset: åŸå§‹æ•°æ®é›†ï¼ˆå¦‚ MNISTï¼‰
    :param num_clients: å®¢æˆ·ç«¯æ€»æ•°
    :return: (å®¢æˆ·ç«¯æ•°æ®é›†, å®¢æˆ·ç«¯æ•°æ®å¤§å°)
    """
    # æ‰‹åŠ¨åˆ’åˆ†çš„æ ·æœ¬æ•°é‡ï¼ˆæ¯ä¸ªå®¢æˆ·ç«¯ 10 ä¸ªç±»åˆ«çš„æ•°æ®é‡ï¼‰
    # client_data_sizes = {
    #     0: {0: 600, 1: 700, 2: 600, 3: 600, 4: 500, 5: 500, 6: 100, 7: 100, 8: 100, 9: 100},
    #     1: {0: 700, 1: 600, 2: 600, 3: 600, 4: 500, 5: 100, 6: 100, 7: 100, 8: 100, 9: 600},
    #     2: {0: 500, 1: 600, 2: 700, 3: 600, 4: 100, 5: 100, 6: 100, 7: 100, 8: 600, 9: 500},
    #     3: {0: 600, 1: 600, 2: 500, 3: 100, 4: 100, 5: 100, 6: 100, 7: 500, 8: 500, 9: 700},
    #     4: {0: 600, 1: 500, 2: 100, 3: 100, 4: 100, 5: 100, 6: 600, 7: 700, 8: 500, 9: 500},
    #     5: {0: 500, 1: 100, 2: 100, 3: 100, 4: 100, 5: 600, 6: 500, 7: 600, 8: 700, 9: 600},
    #     6: {0: 100, 1: 100, 2: 100, 3: 100, 4: 700, 5: 500, 6: 600, 7: 500, 8: 500, 9: 600},
    #     7: {0: 100, 1: 100, 2: 100, 3: 600, 4: 500, 5: 600, 6: 500, 7: 600, 8: 500, 9: 100},
    #     8: {0: 100, 1: 100, 2: 500, 3: 500, 4: 600, 5: 500, 6: 600, 7: 500, 8: 100, 9: 100},
    #     9: {0: 100, 1: 700, 2: 600, 3: 600, 4: 600, 5: 500, 6: 600, 7: 100, 8: 100, 9: 100}
    # }

    client_data_sizes = {
        0: {0: 600},
        1: {1: 700},
        2: {2: 500},
        3: {3: 600},
        4: {4: 600},
        5: {5: 500},
        6: {6: 100},
        7: {7: 100},
        8: {8: 100},
        9: {9: 100}
    }



    # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ•°æ®ç´¢å¼•
    label_to_indices = {i: [] for i in range(10)}  # è®°å½•æ¯ä¸ªç±»åˆ«çš„ç´¢å¼•
    for idx, (_, label) in enumerate(dataset):
        label_to_indices[label].append(idx)

    # åˆå§‹åŒ–å®¢æˆ·ç«¯æ•°æ®å­˜å‚¨
    client_data_subsets = {}
    client_actual_sizes = {i: {label: 0 for label in range(10)} for i in range(num_clients)}  # è®°å½•å®é™…åˆ†é…çš„æ•°æ®é‡

    # éå†æ¯ä¸ªå®¢æˆ·ç«¯ï¼Œä¸ºå…¶åˆ†é…æŒ‡å®šç±»åˆ«çš„æ•°æ®
    for client_id, label_info in client_data_sizes.items():
        selected_indices = []  # ä¸´æ—¶å­˜å‚¨è¯¥å®¢æˆ·ç«¯æ‰€æœ‰é€‰ä¸­çš„ç´¢å¼•
        for label, size in label_info.items():
            # ç¡®ä¿ä¸è¶…å‡ºç±»åˆ«æ•°æ®é›†å®é™…å¤§å°
            available_size = len(label_to_indices[label])
            sample_size = min(available_size, size)

            if sample_size < size:
                print(f"âš ï¸ è­¦å‘Šï¼šç±»åˆ« {label} çš„æ•°æ®ä¸è¶³ï¼Œå®¢æˆ·ç«¯ {client_id} åªèƒ½è·å– {sample_size} æ¡æ ·æœ¬ï¼ˆéœ€æ±‚ {size} æ¡ï¼‰")

            # ä»è¯¥ç±»åˆ«ä¸­éšæœºæŠ½å–æ ·æœ¬
            sampled_indices = random.sample(label_to_indices[label], sample_size)
            selected_indices.extend(sampled_indices)

            # è®°å½•å®é™…åˆ†é…çš„æ•°æ®é‡
            client_actual_sizes[client_id][label] = sample_size

        # åˆ›å»º PyTorch Subset
        client_data_subsets[client_id] = torch.utils.data.Subset(dataset, selected_indices)

    # æ‰“å°æ¯ä¸ªå®¢æˆ·ç«¯çš„å®é™…åˆ†é…æ•°æ®é‡
    print("\nğŸ“Š æ¯ä¸ªå®¢æˆ·ç«¯å®é™…æ•°æ®åˆ†å¸ƒ:")
    for client_id, label_sizes in client_actual_sizes.items():
        print(f"å®¢æˆ·ç«¯ {client_id}: {label_sizes}")

    return client_data_subsets, client_actual_sizes


# æœ¬åœ°è®­ç»ƒå‡½æ•°
def local_train(model, train_loader, epochs=5, lr=0.01):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr)
    model.train()
    for epoch in range(epochs):
        for batch_x, batch_y in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
    return model.state_dict()


#  è”é‚¦å¹³å‡èšåˆå‡½æ•°
def fed_avg(global_model, client_state_dicts, client_sizes):
    global_dict = global_model.state_dict()
    subkey = [sublist[0] for sublist in client_state_dicts]
    new_client_sizes = dict(([(key, client_sizes[key]) for key in subkey]))
    total_data = sum(sum(label_sizes.values()) for label_sizes in new_client_sizes.values())  # è®¡ç®—æ‰€æœ‰å®¢æˆ·ç«¯æ•°æ®æ€»é‡
    for key in global_dict.keys():
        global_dict[key] = sum(
            client_state[key] * (sum(new_client_sizes[client_id].values()) / total_data)
            for (client_id, client_state) in client_state_dicts
        )
    global_model.load_state_dict(global_dict)
    return global_model


# è¯„ä¼°æ¨¡å‹
def evaluate(model, test_loader):
    model.eval()
    criterion = nn.CrossEntropyLoss()
    correct, total, total_loss = 0, 0, 0.0
    with torch.no_grad():
        for batch_x, batch_y in test_loader:
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += batch_y.size(0)
            correct += (predicted == batch_y).sum().item()
    accuracy = correct / total * 100
    return total_loss / len(test_loader), accuracy


def calculate_GRC(global_model, client_models):

    # è·å–æ‰€æœ‰æ¨¡å‹çš„å‚æ•°å¹¶å±•å¹³
    all_params = []

    # é¦–å…ˆè·å–å…¨å±€æ¨¡å‹å‚æ•°
    global_params = []
    for _, param in global_model.named_parameters():
        global_params.append(param.detach().numpy().flatten())
    global_seq = np.concatenate(global_params)
    all_params.append(global_seq)

    # è·å–æ‰€æœ‰å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°
    client_seqs = []
    for client_model in client_models:
        client_params = []
        for _, param in client_model.named_parameters():
            client_params.append(param.detach().numpy().flatten())
        client_seq = np.concatenate(client_params)
        client_seqs.append(client_seq)
        all_params.append(client_seq)

    # è½¬æ¢ä¸ºäºŒç»´æ•°ç»„ (11ä¸ªæ¨¡å‹ x å‚æ•°æ•°é‡)
    param_matrix = np.vstack(all_params)

    # æ”¹è¿›çš„å½’ä¸€åŒ–æ–¹æ³•ï¼šå¯¹æ¯ä¸ªå‚æ•°ä½ç½®(åˆ—)è¿›è¡Œå½’ä¸€åŒ–
    # è®¡ç®—æ¯ä¸ªä½ç½®çš„æ€»å’Œ(è·¨æ¨¡å‹)
    col_sums = param_matrix.sum(axis=0)
    # é¿å…é™¤ä»¥é›¶
    col_sums[col_sums == 0] = 1e-8
    # å½’ä¸€åŒ–
    norm_matrix = param_matrix / col_sums

    # åˆ†ç¦»å‡ºå…¨å±€å’Œå®¢æˆ·ç«¯åºåˆ—
    global_norm = norm_matrix[0]
    client_norms = norm_matrix[1:]

    # è®¡ç®—æ¯ä¸ªå®¢æˆ·ç«¯çš„GRC
    grc_values = []
    for client_norm in client_norms:
        delta = np.abs(global_norm - client_norm)
        delta_min = delta.min()
        delta_max = delta.max()
        rho = 0.5  # åˆ†è¾¨ç³»æ•°

        epsilon = 1e-8
        grc = (delta_min + rho * delta_max) / (delta + rho * delta_max + epsilon)
        grc_values.append(grc.mean())

    return np.array(grc_values)


def select_clients(client_loaders, use_all_clients=False, num_select=None,
                   select_by_loss=False, global_model=None, grc=False):

    if grc is True:
        client_models = []
        for client_id, client_loader in client_loaders.items():
            local_model = MLPModel()
            local_model.load_state_dict(global_model.state_dict())
            local_state = local_train(local_model, client_loader, epochs=1, lr=0.01)
            client_models.append(local_model)
        grc_scores = calculate_GRC(global_model, client_models)

        client_grc_pairs = [(client_id, score) for client_id, score in zip(client_loaders.keys(), grc_scores)]

        client_grc_pairs.sort(key=lambda x: x[1])

        selected = [client_id for client_id, _ in client_grc_pairs[:2]]

        return selected

    # å…¶ä½™é€‰æ‹©é€»è¾‘ä¿æŒä¸å˜
    if use_all_clients is True:
        print("Selecting all clients")
        return list(client_loaders.keys())

    if num_select is None:
        raise ValueError("If use_all_clients=False, num_select cannot be None!")

    if select_by_loss and global_model:
        client_losses = {}
        for client_id, loader in client_loaders.items():
            loss, _ = evaluate(global_model, loader)
            client_losses[client_id] = loss

        selected_clients = sorted(client_losses, key=client_losses.get, reverse=True)[:num_select]
        print(f"Selected {num_select} clients with the highest loss: {selected_clients}")
    else:
        selected_clients = random.sample(list(client_loaders.keys()), num_select)
        print(f"Randomly selected {num_select} clients: {selected_clients}")

    return selected_clients


def entropy_weight(X): # è¾“å…¥ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åˆ†åˆ«ä¸ºæ¯ä¸ªclientçš„ä¸åŒç‰¹å¾çš„GRCç»„æˆçš„åˆ—è¡¨

    P = X / X.sum(axis=0)


    K = 1 / np.log(len(X))
    E = -K * (P * np.log(P)).sum(axis=0)

    W = (1 - E) / (1 - E).sum()
    return W


def update_communication_counts(communication_counts, selected_clients, event):
    """
    å®¢æˆ·ç«¯é€šä¿¡è®¡æ•°
    - event='receive' è¡¨ç¤ºå®¢æˆ·ç«¯æ¥æ”¶åˆ°å…¨å±€æ¨¡å‹
    - event='send' è¡¨ç¤ºå®¢æˆ·ç«¯ä¸Šä¼ æœ¬åœ°æ¨¡å‹
    - event='full_round' ä»…åœ¨å®¢æˆ·ç«¯å®Œæˆå®Œæ•´æ”¶å‘æ—¶å¢åŠ 
    """
    for client_id in selected_clients:
        communication_counts[client_id][event] += 1

        # ä»…å½“å®¢æˆ·ç«¯å®Œæˆä¸€æ¬¡å®Œæ•´çš„ send å’Œ receive æ—¶å¢åŠ  full_round
        if event == "send" and communication_counts[client_id]['receive'] > 0:
            communication_counts[client_id]['full_round'] += 1


def main():
    torch.manual_seed(0)
    random.seed(0)
    np.random.seed(0)

    # åŠ è½½ MNIST æ•°æ®é›†
    train_data, test_data = load_mnist_data()

    # ç”Ÿæˆå®¢æˆ·ç«¯æ•°æ®é›†ï¼Œæ¯ä¸ªå®¢æˆ·ç«¯åŒ…å«å¤šä¸ªç±»åˆ«
    client_datasets, client_data_sizes = split_data_by_label(train_data)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    client_loaders = {client_id: data.DataLoader(dataset, batch_size=32, shuffle=True)
                      for client_id, dataset in client_datasets.items()}
    test_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)

    # åˆå§‹åŒ–å…¨å±€æ¨¡å‹
    global_model = MLPModel()
    global_accuracies = []  # è®°å½•æ¯è½®å…¨å±€æ¨¡å‹çš„æµ‹è¯•é›†å‡†ç¡®ç‡
    total_communication_counts = []  # è®°å½•æ¯è½®å®¢æˆ·ç«¯é€šä¿¡æ¬¡æ•°
    rounds = 300  # è”é‚¦å­¦ä¹ è½®æ•°
    use_all_clients = False  # æ˜¯å¦è¿›è¡Œå®¢æˆ·ç«¯é€‰æ‹©
    num_selected_clients = 2  # æ¯è½®é€‰æ‹©å®¢æˆ·ç«¯è®­ç»ƒæ•°é‡
    use_loss_based_selection = True  # æ˜¯å¦æ ¹æ® loss é€‰æ‹©å®¢æˆ·ç«¯
    grc = False

    # åˆå§‹åŒ–é€šä¿¡è®¡æ•°å™¨
    communication_counts = {}
    for client_id in client_loaders.keys():
        communication_counts[client_id] = {
            'send': 0,  # è®°å½•å‘é€æ¬¡æ•°
            'receive': 0,  # è®°å½•æ¥æ”¶æ¬¡æ•°
            'full_round': 0  # è®°å½•å®Œæ•´æ”¶å‘æ¬¡æ•°
        }
    # å®éªŒæ•°æ®å­˜å‚¨ CSV
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"training_data_{timestamp}.csv"
    csv_data = []

    for r in range(rounds):
        print(f"\nğŸ”„ ç¬¬ {r + 1} è½®èšåˆ")
        # é€‰æ‹©å®¢æˆ·ç«¯
        if r % 3 == 0:
            selected_clients = select_clients(client_loaders, use_all_clients=use_all_clients,
                                          num_select=num_selected_clients,
                                          select_by_loss=use_loss_based_selection, global_model=global_model, grc=grc)

        # # è®¾ç½®éšæœºé˜»æ–­æŸä¸ªå®¢æˆ·ç«¯çš„æ¥æ”¶è®°å½•ï¼ˆéªŒè¯ç”¨ï¼‰
        # blocked_client = random.choice(selected_clients)
        # print(f" Blocking client {blocked_client} from receiving, skipping the receive event record.")

        # for client_id in selected_clients:
        #     if client_id == blocked_client:
        #         continue  # ç›´æ¥è·³è¿‡ receive è®°å½•
        #     update_communication_counts(communication_counts, [client_id], "receive")

        # è®°å½•å®¢æˆ·ç«¯æ¥æ”¶é€šä¿¡æ¬¡æ•°
        update_communication_counts(communication_counts, selected_clients, "receive")
        client_state_dicts = []

        # å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
        for client_id in selected_clients:
            client_loader = client_loaders[client_id]
            local_model = MLPModel()
            local_model.load_state_dict(global_model.state_dict())  # å¤åˆ¶å…¨å±€æ¨¡å‹å‚æ•°
            local_state = local_train(local_model, client_loader, epochs=1, lr=0.01)  # è®­ç»ƒ 1 è½®
            client_state_dicts.append((client_id, local_state))  # å­˜å‚¨ (å®¢æˆ·ç«¯ID, è®­ç»ƒåçš„å‚æ•°)

            update_communication_counts(communication_counts, [client_id], "send")  # è®°å½•å®¢æˆ·ç«¯ä¸ŠæŠ¥é€šä¿¡æ¬¡æ•°

            param_mean = {name: param.mean().item() for name, param in local_model.named_parameters()}
            print(f"  âœ… å®¢æˆ·ç«¯ {client_id} è®­ç»ƒå®Œæˆ | æ ·æœ¬æ•°é‡: {sum(client_data_sizes[client_id].values())}")
            print(f"  ğŸ“Œ å®¢æˆ·ç«¯ {client_id} æ¨¡å‹å‚æ•°å‡å€¼: {param_mean}")

        # è®¡ç®—æœ¬è½®é€šä¿¡æ¬¡æ•°
        total_send = sum(
            communication_counts[c]['send'] - (communication_counts[c]['full_round'] - 1) for c in selected_clients)
        total_receive = sum(
            communication_counts[c]['receive'] - (communication_counts[c]['full_round'] - 1) for c in selected_clients)
        total_comm = total_send + total_receive  # æ¯è½®ç‹¬ç«‹çš„æ€»é€šä¿¡æ¬¡æ•°
        total_communication_counts.append(total_comm)  # è®°å½•å½“å‰è½®çš„é€šä¿¡æ¬¡æ•°

        # èšåˆæ¨¡å‹å‚æ•°
        global_model = fed_avg(global_model, client_state_dicts, client_data_sizes)

        # # è®¡ç®—å…¨å±€æ¨¡å‹å‚æ•°å¹³å‡å€¼
        # global_param_mean = {name: param.mean().item() for name, param in global_model.named_parameters()}
        # print(f"ğŸ”„ è½® {r + 1} ç»“æŸåï¼Œå…¨å±€æ¨¡å‹å‚æ•°å‡å€¼: {global_param_mean}")

        # è¯„ä¼°æ¨¡å‹
        loss, accuracy = evaluate(global_model, test_loader)
        global_accuracies.append(accuracy)
        print(f"ğŸ“Š æµ‹è¯•é›†æŸå¤±: {loss:.4f} | æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.2f}%")

        # è®°å½•æ•°æ®åˆ° CSV
        csv_data.append([
            r + 1,
            accuracy,
            total_comm,
            ",".join(map(str, selected_clients))
        ])

    # ä¿å­˜æ•°æ®åˆ° CSV æ–‡ä»¶
    df = pd.DataFrame(csv_data, columns=[
        'Round', 'Accuracy', 'Total communication counts', 'Selected Clients'
    ])
    df.to_csv(csv_filename, index=False)
    print(f"è®­ç»ƒæ•°æ®å·²ä¿å­˜è‡³ {csv_filename}")

    # è¾“å‡ºæœ€ç»ˆæ¨¡å‹çš„æ€§èƒ½
    final_loss, final_accuracy = evaluate(global_model, test_loader)
    print(f"\nğŸ¯ Loss of final model test dataset: {final_loss:.4f}")
    print(f"ğŸ¯ Final model test set accuracy: {final_accuracy:.2f}%")

    # è¾“å‡ºé€šä¿¡è®°å½•
    print("\n Client Communication Statistics:")
    for client_id, counts in communication_counts.items():
        print(
            f"Client {client_id}: Sent {counts['send']} times, Received {counts['receive']} times, Completed full_round {counts['full_round']} times")

    # å¯è§†åŒ–å…¨å±€æ¨¡å‹å‡†ç¡®ç‡ vs è½®æ¬¡
    plt.figure(figsize=(8, 5))
    plt.plot(range(1, rounds + 1), global_accuracies, marker='o', linestyle='-', color='b', label="Test Accuracy")
    plt.xlabel("Federated Learning Rounds")
    plt.ylabel("Accuracy")
    plt.title("Test Accuracy Over Federated Learning Rounds")
    plt.legend()
    plt.grid(True)
    plt.show()

    # å¯è§†åŒ–å…¨å±€æ¨¡å‹å‡†ç¡®ç‡ vs å®¢æˆ·ç«¯å®Œæ•´é€šä¿¡æ¬¡æ•°
    plt.figure(figsize=(8, 5))
    plt.plot(total_communication_counts, global_accuracies, marker='s', linestyle='-', color='r',
             label="Test Accuracy vs. Communication")
    plt.xlabel("Total Communication Count per Round")
    plt.ylabel("Accuracy")
    plt.title("Test Accuracy vs. Total Communication")
    plt.legend()
    plt.grid(True)
    plt.show()


def main2():
    torch.manual_seed(0)
    random.seed(0)
    np.random.seed(0)

    # åŠ è½½ MNIST æ•°æ®é›†
    train_data, test_data = load_mnist_data()

    # ç”Ÿæˆå®¢æˆ·ç«¯æ•°æ®é›†ï¼Œæ¯ä¸ªå®¢æˆ·ç«¯åŒ…å«å¤šä¸ªç±»åˆ«
    client_datasets, client_data_sizes = split_data_by_label(train_data)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    client_loaders = {client_id: data.DataLoader(dataset, batch_size=32, shuffle=True)
                      for client_id, dataset in client_datasets.items()}
    test_loader = data.DataLoader(test_data, batch_size=32, shuffle=False)

    # åˆå§‹åŒ–å…¨å±€æ¨¡å‹
    global_model = MLPModel()
    global_accuracies = []
    total_communication_counts = []
    rounds = 300
    use_all_clients = False
    num_selected_clients = 2
    use_loss_based_selection = True
    grc = False

    # åˆå§‹åŒ–é€šä¿¡è®¡æ•°å™¨
    communication_counts = {}
    for client_id in client_loaders.keys():
        communication_counts[client_id] = {
            'send': 0,
            'receive': 0,
            'full_round': 0
        }

    # æ–°å¢ï¼šç”¨äºè®°å½•å®¢æˆ·ç«¯å†å²loss
    client_loss_history = {client_id: [] for client_id in client_loaders.keys()}
    client_selection_history = []  # è®°å½•æ¯è½®é€‰æ‹©çš„å®¢æˆ·ç«¯

    # å®éªŒæ•°æ®å­˜å‚¨ CSV
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"training_data_{timestamp}.csv"
    csv_data = []

    for r in range(rounds):
        print(f"\nğŸ”„ ç¬¬ {r + 1} è½®èšåˆ")

        # é€‰æ‹©å®¢æˆ·ç«¯
        if r % 3 == 0:
            # æ¯3è½®è®¡ç®—ä¸€æ¬¡æ‰€æœ‰å®¢æˆ·ç«¯çš„loss
            current_losses = {}
            for client_id, loader in client_loaders.items():
                loss, _ = evaluate(global_model, loader)
                current_losses[client_id] = loss
                client_loss_history[client_id].append(loss)

            # å¯¹äºæœ€è¿‘è¢«é€‰ä¸­çš„å®¢æˆ·ç«¯ï¼Œä½¿ç”¨åŠ æƒå¹³å‡loss
            weighted_losses = {}
            for client_id in client_loaders.keys():
                if len(client_selection_history) > 0 and client_id in client_selection_history[-1]:
                    # æœ€è¿‘è¢«é€‰ä¸­çš„å®¢æˆ·ç«¯ï¼Œè®¡ç®—åŠ æƒå¹³å‡loss
                    history = client_loss_history[client_id][-3:]  # å–æœ€è¿‘3æ¬¡loss
                    weights = [0.5, 0.3, 0.2]  # åŠ æƒç³»æ•°ï¼Œæœ€è¿‘çš„æœ€é‡è¦
                    weighted_loss = sum(h * w for h, w in zip(history, weights)) / sum(weights)
                    weighted_losses[client_id] = weighted_loss
                else:
                    # å…¶ä»–å®¢æˆ·ç«¯ä½¿ç”¨å½“å‰loss
                    weighted_losses[client_id] = current_losses[client_id]

            # é€‰æ‹©lossæœ€å¤§çš„2ä¸ªå®¢æˆ·ç«¯
            selected_clients = sorted(weighted_losses, key=weighted_losses.get, reverse=True)[:num_selected_clients]
            print(f"Selected {num_selected_clients} clients with the highest weighted loss: {selected_clients}")

        client_selection_history.append(selected_clients)  # è®°å½•é€‰æ‹©å†å²

        # è®°å½•å®¢æˆ·ç«¯æ¥æ”¶é€šä¿¡æ¬¡æ•°
        update_communication_counts(communication_counts, selected_clients, "receive")
        client_state_dicts = []

        # å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
        for client_id in selected_clients:
            client_loader = client_loaders[client_id]
            local_model = MLPModel()
            local_model.load_state_dict(global_model.state_dict())
            local_state = local_train(local_model, client_loader, epochs=1, lr=0.01)
            client_state_dicts.append((client_id, local_state))

            update_communication_counts(communication_counts, [client_id], "send")

            param_mean = {name: param.mean().item() for name, param in local_model.named_parameters()}
            print(f"  âœ… å®¢æˆ·ç«¯ {client_id} è®­ç»ƒå®Œæˆ | æ ·æœ¬æ•°é‡: {sum(client_data_sizes[client_id].values())}")

        # è®¡ç®—æœ¬è½®é€šä¿¡æ¬¡æ•°
        total_send = sum(
            communication_counts[c]['send'] - (communication_counts[c]['full_round'] - 1) for c in selected_clients)
        total_receive = sum(
            communication_counts[c]['receive'] - (communication_counts[c]['full_round'] - 1) for c in
            selected_clients)
        total_comm = total_send + total_receive
        total_communication_counts.append(total_comm)

        # èšåˆæ¨¡å‹å‚æ•°
        global_model = fed_avg(global_model, client_state_dicts, client_data_sizes)

        # è¯„ä¼°æ¨¡å‹
        loss, accuracy = evaluate(global_model, test_loader)
        global_accuracies.append(accuracy)
        print(f"ğŸ“Š æµ‹è¯•é›†æŸå¤±: {loss:.4f} | æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.2f}%")

        # è®°å½•æ•°æ®åˆ° CSV
        csv_data.append([
            r + 1,
            accuracy,
            total_comm,
            ",".join(map(str, selected_clients))
        ])

    # ä¿å­˜æ•°æ®åˆ° CSV æ–‡ä»¶
    df = pd.DataFrame(csv_data, columns=[
        'Round', 'Accuracy', 'Total communication counts', 'Selected Clients'
    ])
    df.to_csv(csv_filename, index=False)
    print(f"è®­ç»ƒæ•°æ®å·²ä¿å­˜è‡³ {csv_filename}")

    # è¾“å‡ºæœ€ç»ˆæ¨¡å‹çš„æ€§èƒ½
    final_loss, final_accuracy = evaluate(global_model, test_loader)
    print(f"\nğŸ¯ Loss of final model test dataset: {final_loss:.4f}")
    print(f"ğŸ¯ Final model test set accuracy: {final_accuracy:.2f}%")

    # å¯è§†åŒ–ç»“æœ
    plt.figure(figsize=(8, 5))
    plt.plot(range(1, rounds + 1), global_accuracies, marker='o', linestyle='-', color='b', label="Test Accuracy")
    plt.xlabel("Federated Learning Rounds")
    plt.ylabel("Accuracy")
    plt.title("Test Accuracy Over Federated Learning Rounds")
    plt.legend()
    plt.grid(True)
    plt.show()


if __name__ == "__main__":
    main()

# 4,7 GRC
# 5,8 loss
# 6,9 total
# 10 loss choose per 3 times
# 11 prc choose per 3 times
# 12 loss weight mean choose per 3 times